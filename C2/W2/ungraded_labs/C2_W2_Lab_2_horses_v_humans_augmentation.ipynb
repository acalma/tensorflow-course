{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W2/ungraded_labs/C2_W2_Lab_2_horses_v_humans_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37v_yExZppEp"
   },
   "source": [
    "# Ungraded Lab: Data Augmentation on the Horses or Humans Dataset\n",
    "\n",
    "In the previous lab, you saw how data augmentation helped improve the model's performance on unseen data. By tweaking the cat and dog training images, the model was able to learn features that are also representative of the validation data. However, applying data augmentation requires good understanding of your dataset. Simply transforming it randomly will not always yield good results. \n",
    "\n",
    "In the next cells, you will apply the same techniques to the `Horses or Humans` dataset and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:13:38.431536Z",
     "start_time": "2024-05-19T04:13:33.264532Z"
    },
    "id": "Lslf0vB3rQlU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-19 04:13:33--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.186.91, 142.250.186.59, 142.250.181.251, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.186.91|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 149574867 (143M) [application/zip]\r\n",
      "Saving to: ‘horse-or-human.zip’\r\n",
      "\r\n",
      "100%[======================================>] 149,574,867 37.4MB/s   in 4.8s   \r\n",
      "\r\n",
      "2024-05-19 04:13:38 (29.7 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Download the training set\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:13:19.006183Z",
     "start_time": "2024-05-19T04:13:17.756833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-19 04:13:17--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.16.155, 216.58.206.91, 142.250.74.219, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.16.155|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 11480187 (11M) [application/zip]\r\n",
      "Saving to: ‘validation-horse-or-human.zip’\r\n",
      "\r\n",
      "100%[======================================>] 11,480,187  11.8MB/s   in 0.9s   \r\n",
      "\r\n",
      "2024-05-19 04:13:18 (11.8 MB/s) - ‘validation-horse-or-human.zip’ saved [11480187/11480187]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Download the validation set\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:40.937289Z",
     "start_time": "2024-05-19T04:15:40.214501Z"
    },
    "id": "RXZT2UsyIVe_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Extract the archive\n",
    "zip_ref = zipfile.ZipFile('./horse-or-human.zip', 'r')\n",
    "zip_ref.extractall('tmp/horse-or-human')\n",
    "\n",
    "zip_ref = zipfile.ZipFile('./validation-horse-or-human.zip', 'r')\n",
    "zip_ref.extractall('tmp/validation-horse-or-human')\n",
    "\n",
    "zip_ref.close()\n",
    "\n",
    "# Directory with training horse pictures\n",
    "train_horse_dir = os.path.join('tmp/horse-or-human/horses')\n",
    "\n",
    "# Directory with training human pictures\n",
    "train_human_dir = os.path.join('tmp/horse-or-human/humans')\n",
    "\n",
    "# Directory with validation horse pictures\n",
    "validation_horse_dir = os.path.join('tmp/validation-horse-or-human/horses')\n",
    "\n",
    "# Directory with validation human pictures\n",
    "validation_human_dir = os.path.join('tmp/validation-horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:43.907489Z",
     "start_time": "2024-05-19T04:15:40.939091Z"
    },
    "id": "PixZ2s5QbYQ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 04:15:41.315381: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 04:15:41.361352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 04:15:41.361384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 04:15:41.362533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-19 04:15:41.369505: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 04:15:42.190876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-19 04:15:43.361907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.410026: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.411726: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.413922: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.415575: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.417172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.555339: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.556504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.557529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-19 04:15:43.558524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:43.924243Z",
     "start_time": "2024-05-19T04:15:43.909603Z"
    },
    "id": "8DHWhFP_uhq3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Set training parameters\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:43.969440Z",
     "start_time": "2024-05-19T04:15:43.925472Z"
    },
    "id": "ClebU9NJg99G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Apply data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'tmp/horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'tmp/validation-horse-or-human/',  # This is the source directory for validation images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:23:34.783687Z",
     "start_time": "2024-05-19T04:23:34.776384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_available = tf.config.list_physical_devices('GPU')\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:23:34.774606Z",
     "start_time": "2024-05-19T04:15:44.204680Z"
    },
    "id": "Fb1_lgobv81m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 04:15:50.716482: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-19 04:15:53.343052: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ffa78aaa4e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-19 04:15:53.343083: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-05-19 04:15:53.348863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716092153.417999   21993 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 25s 2s/step - loss: 0.6901 - accuracy: 0.5573 - val_loss: 0.6843 - val_accuracy: 0.8672\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6884 - accuracy: 0.5973 - val_loss: 0.6773 - val_accuracy: 0.7383\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6850 - accuracy: 0.5651 - val_loss: 0.6763 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 22s 3s/step - loss: 0.6799 - accuracy: 0.5295 - val_loss: 0.6690 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6737 - accuracy: 0.6352 - val_loss: 0.6487 - val_accuracy: 0.6523\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.6621 - accuracy: 0.6807 - val_loss: 0.7235 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6635 - accuracy: 0.5984 - val_loss: 0.6117 - val_accuracy: 0.8359\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6430 - accuracy: 0.7253 - val_loss: 0.5896 - val_accuracy: 0.8398\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6345 - accuracy: 0.6852 - val_loss: 0.6020 - val_accuracy: 0.6289\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6017 - accuracy: 0.7119 - val_loss: 0.6495 - val_accuracy: 0.5195\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.5850 - accuracy: 0.7236 - val_loss: 0.7475 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.6009 - accuracy: 0.6541 - val_loss: 0.6092 - val_accuracy: 0.5664\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.5545 - accuracy: 0.7230 - val_loss: 0.5758 - val_accuracy: 0.6523\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.5389 - accuracy: 0.7264 - val_loss: 0.8090 - val_accuracy: 0.5078\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.5289 - accuracy: 0.7363 - val_loss: 0.7005 - val_accuracy: 0.5391\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.5329 - accuracy: 0.7253 - val_loss: 0.6822 - val_accuracy: 0.5547\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.5335 - accuracy: 0.7464 - val_loss: 0.6106 - val_accuracy: 0.6328\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.5324 - accuracy: 0.7442 - val_loss: 0.6702 - val_accuracy: 0.5977\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.5101 - accuracy: 0.7508 - val_loss: 0.6520 - val_accuracy: 0.6211\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.4921 - accuracy: 0.7753 - val_loss: 0.7008 - val_accuracy: 0.6211\n"
     ]
    }
   ],
   "source": [
    "# Constant for epochs\n",
    "EPOCHS = 20\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zNPRWOVJdOH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the model results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwyabYvCsvtn"
   },
   "source": [
    "As you can see in the results, the preprocessing techniques used in augmenting the data did not help much in the results. The validation accuracy is fluctuating and not trending up like the training accuracy. This might be because the additional training data generated still do not represent the features in the validation data. For example, some human or horse poses in the validation set cannot be mimicked by the image processing techniques that `ImageDataGenerator` provides. It might also be that the background of the training images are also learned so the white background of the validation set is throwing the model off even with cropping. Try looking at the validation images in the `tmp/validation-horse-or-human` directory (note: if you are using Colab, you can use the file explorer on the left to explore the images) and see if you can augment the training images to match its characteristics. If this is not possible, then at this point you can consider other techniques and you will see that in next week's lessons."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C2_W2_Lab_2_horses_v_humans_augmentation.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W2/ungraded_labs/C2_W2_Lab_2_horses_v_humans_augmentation.ipynb",
     "timestamp": 1639648217641
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
